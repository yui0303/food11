{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This example show you how to train a classifier using pytorch framework:\n",
    "\n",
    "\n",
    "## step\n",
    "--------------------\n",
    "0. check your device\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolution Neural Network\n",
    "3. Define a loss function and optimizer\n",
    "4. Train the network\n",
    "5. Test the network on the test data\n",
    "--------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "## 0. check your device\n",
    "\n",
    "In the beginning, you have to be sure you have your gpu device available.\n",
    "\n",
    "    [Remark] if you want to utilize GPUs for computation, you should check your system supports to CUDA.\n",
    "    (refer the following step)\n",
    "\n",
    "    [Remark] Pytorch have two types of tensor, one is CPU tensor types, another is CUDA tensor types. \n",
    "    GPU only can use CUDA tensor types for computation. \n",
    "\n",
    "-[Official document]: https://pytorch.org/docs/stable/cuda.html\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Check devices..\n",
      "Current device:  cuda\n",
      "Our selected device:  0\n",
      "1  GPUs is available\n"
     ]
    }
   ],
   "source": [
    "#To determine if your system supports CUDA\n",
    "print(\"==> Check devices..\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Current device: \",device)\n",
    "\n",
    "#Also can print your current GPU id, and the number of GPUs you can use.\n",
    "print(\"Our selected device: \", torch.cuda.current_device())\n",
    "print(torch.cuda.device_count(), \" GPUs is available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "## 1. Load and normalizing the CIFAR10 training and test datasets using torchvision\n",
    "\n",
    "\n",
    "1.1     Before building the dataset, knowing how to do data preprocessing is very important. Pytorch provides a package called \"torchvision\", it consists of some functions for image transformation, like: normalization, rotation, resize...etc., or if the provided functions didn't meet the needs, you can to use other libraries or tools to preprocess the data.\n",
    "   \n",
    "\n",
    "1.2     Pytorch provides a class called \"dataset\", you can create a subclass of it to format your raw data to a more suitable format for DataLoader. Fortunately, pytorch provided some popular datasets, model architectures, and functions of image transformation in \"torchvision\".\n",
    "\n",
    "\n",
    "    [Remark] If you want to build a pytorch dataset for your own data. One you can do is rewriting a new subclass of original dataset class, and anothor is using the API called \"ImageFolder\" to load your dataset. The return of the \"ImageFolder\" is also a pytorch dataset class. However, you should adjust the directory architecture to match the need of \"ImageFolder\". \n",
    "\n",
    "\n",
    "1.3     After defining \"Dataset\" class, you can start to define a \"DataLoader\" class. You can easily to do \"Minibatch training\" by DataLoader. \"Minibatch training\" means DataLoader will separate your dataset into several batch. And each batch consists fixed number of data depend on what batch size you set.\n",
    "\n",
    "\n",
    "-[How to load common dataset]: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "\n",
    "-[How to use ImageFolder]: https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#afterword-torchvision\n",
    "\n",
    "-[torchvision document]: https://pytorch.org/docs/stable/torchvision/index.html\n",
    "\n",
    "-[torchvision sourcecode]: https://github.com/pytorch/vision/tree/master/torchvision\n",
    "\n",
    "-[Dataset, DataLoader, DataLoaderIter document]: https://pytorch.org/docs/stable/data.html\n",
    "\n",
    "-[Dataset, DataLoader, DataLoaderIter sourcecode]: https://pytorch.org/docs/stable/_modules/torch/utils/data/dataset.html#Dataset\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing dataset..\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing dataset..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1.1\"\"\"\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1]\n",
    "# We transform them to Tensor type\n",
    "# And normalize the data\n",
    "# Be sure you do same normalization for your train and test data\n",
    "\n",
    "#The transform function for train data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "#The transform function for test data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1.2\"\"\" \n",
    "\n",
    "#Use API to load CIFAR10 train dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='/tmp/dataset-nctu', train=True, download=False, transform=transform_train)\n",
    "\n",
    "#Use API to load CIFAR10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='/tmp/dataset-nctu', train=False, download=False, transform=transform_test)\n",
    "\n",
    "#Dataset definition need to know your customized transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1.3\"\"\"\n",
    "\n",
    "#Create DataLoader to draw samples from the dataset\n",
    "#In this case, we define a DataLoader to random sample our dataset. \n",
    "#For single sampling, we take one batch of data. Each batch consists 4 images\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because cifar10 number the data classes in range [0,10]\n",
    "#However, number representation is unreadable for humans\n",
    "#So, we manually set the name of each class\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "\n",
    "# 2. Define a Convolution Neural Network\n",
    "    \n",
    "Neural networks can be constructed using the \"torch.nn\" package, \"torch.nn\" depends on \"autograd\" to define model. A complete model definition contains layers declaration and forwarding methods.\n",
    "\n",
    "    \n",
    "All the model in pytorch inherit the \"nn.Module\" class. You can define new layer via \"torch.nn\" library. And, concatenate these layers into a complete model.\n",
    "\n",
    "\n",
    "-[How to use nn.Module] https://pytorch.org/docs/stable/nn.html#torch.nn.Module\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your own model\n",
    "class Net(nn.Module):\n",
    "\n",
    "    #define the layers\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    #concatenate these layers\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# declare a new model\n",
    "tmp_net = Net()\n",
    "# now, you can see current model architecture\n",
    "print(tmp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# or take a look at one layer of model\n",
    "print(tmp_net.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=15, out_features=2, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# you also can change the layer of model\n",
    "# but can't edit the forward method\n",
    "tmp_net.fc3 = nn.Linear(15,2)\n",
    "print(tmp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=15, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# just edit the parameter of one layer is OK\n",
    "tmp_net.fc3.out_features = 10\n",
    "print(tmp_net)\n",
    "\n",
    "# [Remark] above two method to change the layer\n",
    "# architecture is important in [LAB 1-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare a new model\n",
    "net = Net()\n",
    "# change all model tensor into cuda type\n",
    "# something like weight & bias are the tensor \n",
    "net = net.to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "\n",
    "# 3. Define a Loss function and optimize\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Defining loss function and optimize..\n"
     ]
    }
   ],
   "source": [
    "print('==> Defining loss function and optimize..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimization algorithm\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "\n",
    "# 4. Train the network\n",
    "\n",
    "Before training the model, we need to analysis the tensor variable.\n",
    "\n",
    "\n",
    "Each variable have many attibute, like: .grad_fn, .require_grad, .data, .grad...etc. The \".grad_fn\" attribute of \"torch.Tensor\" is an entry point into the function that has create this \"torch.Tensor\" variables. Because of \".grad_fn\" flag, we can easily create a computing graph in the form of DAG(directed acyclic graph).\n",
    "\n",
    "And then, the \".require_grad\" attribute allows us to determine whether the backward propagation function is going to calculate the gradient of this \"torch.Tensor\" variable. If one variable has a false value of require_grad, it represent that you don't want to calculate this variable's gradient, and also its gradient will not be updated.\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Training model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Training model..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 2.299\n",
      "[1,   400] loss: 2.281\n",
      "[1,   600] loss: 2.211\n",
      "[1,   800] loss: 2.098\n",
      "[1,  1000] loss: 2.028\n",
      "[1,  1200] loss: 1.966\n",
      "[1,  1400] loss: 1.946\n",
      "1 epoch, training accuracy: 22.9860\n",
      "[2,   200] loss: 1.857\n",
      "[2,   400] loss: 1.792\n",
      "[2,   600] loss: 1.758\n",
      "[2,   800] loss: 1.747\n",
      "[2,  1000] loss: 1.726\n",
      "[2,  1200] loss: 1.704\n",
      "[2,  1400] loss: 1.693\n",
      "2 epoch, training accuracy: 36.0240\n",
      "[3,   200] loss: 1.645\n",
      "[3,   400] loss: 1.647\n",
      "[3,   600] loss: 1.635\n",
      "[3,   800] loss: 1.611\n",
      "[3,  1000] loss: 1.585\n",
      "[3,  1200] loss: 1.614\n",
      "[3,  1400] loss: 1.595\n",
      "3 epoch, training accuracy: 41.3540\n",
      "[4,   200] loss: 1.560\n",
      "[4,   400] loss: 1.521\n",
      "[4,   600] loss: 1.543\n",
      "[4,   800] loss: 1.553\n",
      "[4,  1000] loss: 1.526\n",
      "[4,  1200] loss: 1.547\n",
      "[4,  1400] loss: 1.495\n",
      "4 epoch, training accuracy: 44.3260\n",
      "[5,   200] loss: 1.491\n",
      "[5,   400] loss: 1.474\n",
      "[5,   600] loss: 1.476\n",
      "[5,   800] loss: 1.479\n",
      "[5,  1000] loss: 1.440\n",
      "[5,  1200] loss: 1.457\n",
      "[5,  1400] loss: 1.445\n",
      "5 epoch, training accuracy: 46.9660\n",
      "[6,   200] loss: 1.440\n",
      "[6,   400] loss: 1.425\n",
      "[6,   600] loss: 1.431\n",
      "[6,   800] loss: 1.421\n",
      "[6,  1000] loss: 1.382\n",
      "[6,  1200] loss: 1.383\n",
      "[6,  1400] loss: 1.389\n",
      "6 epoch, training accuracy: 49.4560\n",
      "[7,   200] loss: 1.386\n",
      "[7,   400] loss: 1.385\n",
      "[7,   600] loss: 1.386\n",
      "[7,   800] loss: 1.355\n",
      "[7,  1000] loss: 1.347\n",
      "[7,  1200] loss: 1.352\n",
      "[7,  1400] loss: 1.330\n",
      "7 epoch, training accuracy: 51.0960\n",
      "[8,   200] loss: 1.310\n",
      "[8,   400] loss: 1.332\n",
      "[8,   600] loss: 1.331\n",
      "[8,   800] loss: 1.318\n",
      "[8,  1000] loss: 1.326\n",
      "[8,  1200] loss: 1.334\n",
      "[8,  1400] loss: 1.325\n",
      "8 epoch, training accuracy: 52.3280\n",
      "[9,   200] loss: 1.328\n",
      "[9,   400] loss: 1.281\n",
      "[9,   600] loss: 1.260\n",
      "[9,   800] loss: 1.273\n",
      "[9,  1000] loss: 1.283\n",
      "[9,  1200] loss: 1.291\n",
      "[9,  1400] loss: 1.272\n",
      "9 epoch, training accuracy: 54.1900\n",
      "[10,   200] loss: 1.261\n",
      "[10,   400] loss: 1.263\n",
      "[10,   600] loss: 1.262\n",
      "[10,   800] loss: 1.267\n",
      "[10,  1000] loss: 1.245\n",
      "[10,  1200] loss: 1.271\n",
      "[10,  1400] loss: 1.246\n",
      "10 epoch, training accuracy: 55.0280\n",
      "[11,   200] loss: 1.247\n",
      "[11,   400] loss: 1.212\n",
      "[11,   600] loss: 1.215\n",
      "[11,   800] loss: 1.223\n",
      "[11,  1000] loss: 1.243\n",
      "[11,  1200] loss: 1.248\n",
      "[11,  1400] loss: 1.223\n",
      "11 epoch, training accuracy: 55.9800\n",
      "[12,   200] loss: 1.222\n",
      "[12,   400] loss: 1.206\n",
      "[12,   600] loss: 1.221\n",
      "[12,   800] loss: 1.204\n",
      "[12,  1000] loss: 1.194\n",
      "[12,  1200] loss: 1.208\n",
      "[12,  1400] loss: 1.193\n",
      "12 epoch, training accuracy: 57.2300\n",
      "[13,   200] loss: 1.173\n",
      "[13,   400] loss: 1.176\n",
      "[13,   600] loss: 1.192\n",
      "[13,   800] loss: 1.190\n",
      "[13,  1000] loss: 1.185\n",
      "[13,  1200] loss: 1.175\n",
      "[13,  1400] loss: 1.200\n",
      "13 epoch, training accuracy: 58.1780\n",
      "[14,   200] loss: 1.187\n",
      "[14,   400] loss: 1.157\n",
      "[14,   600] loss: 1.176\n",
      "[14,   800] loss: 1.139\n",
      "[14,  1000] loss: 1.156\n",
      "[14,  1200] loss: 1.187\n",
      "[14,  1400] loss: 1.143\n",
      "14 epoch, training accuracy: 58.9020\n",
      "[15,   200] loss: 1.156\n",
      "[15,   400] loss: 1.140\n",
      "[15,   600] loss: 1.145\n",
      "[15,   800] loss: 1.166\n",
      "[15,  1000] loss: 1.125\n",
      "[15,  1200] loss: 1.150\n",
      "[15,  1400] loss: 1.141\n",
      "15 epoch, training accuracy: 58.9900\n",
      "[16,   200] loss: 1.154\n",
      "[16,   400] loss: 1.117\n",
      "[16,   600] loss: 1.122\n",
      "[16,   800] loss: 1.148\n",
      "[16,  1000] loss: 1.154\n",
      "[16,  1200] loss: 1.141\n",
      "[16,  1400] loss: 1.111\n",
      "16 epoch, training accuracy: 59.6600\n",
      "[17,   200] loss: 1.125\n",
      "[17,   400] loss: 1.139\n",
      "[17,   600] loss: 1.092\n",
      "[17,   800] loss: 1.136\n",
      "[17,  1000] loss: 1.094\n",
      "[17,  1200] loss: 1.114\n",
      "[17,  1400] loss: 1.114\n",
      "17 epoch, training accuracy: 60.3240\n",
      "[18,   200] loss: 1.111\n",
      "[18,   400] loss: 1.116\n",
      "[18,   600] loss: 1.122\n",
      "[18,   800] loss: 1.110\n",
      "[18,  1000] loss: 1.102\n",
      "[18,  1200] loss: 1.096\n",
      "[18,  1400] loss: 1.099\n",
      "18 epoch, training accuracy: 60.6900\n",
      "[19,   200] loss: 1.084\n",
      "[19,   400] loss: 1.112\n",
      "[19,   600] loss: 1.089\n",
      "[19,   800] loss: 1.086\n",
      "[19,  1000] loss: 1.110\n",
      "[19,  1200] loss: 1.090\n",
      "[19,  1400] loss: 1.092\n",
      "19 epoch, training accuracy: 61.2480\n",
      "[20,   200] loss: 1.080\n",
      "[20,   400] loss: 1.089\n",
      "[20,   600] loss: 1.085\n",
      "[20,   800] loss: 1.089\n",
      "[20,  1000] loss: 1.092\n",
      "[20,  1200] loss: 1.076\n",
      "[20,  1400] loss: 1.082\n",
      "20 epoch, training accuracy: 61.5320\n",
      "[21,   200] loss: 1.036\n",
      "[21,   400] loss: 1.047\n",
      "[21,   600] loss: 1.066\n",
      "[21,   800] loss: 1.088\n",
      "[21,  1000] loss: 1.086\n",
      "[21,  1200] loss: 1.087\n",
      "[21,  1400] loss: 1.082\n",
      "21 epoch, training accuracy: 62.0540\n",
      "[22,   200] loss: 1.043\n",
      "[22,   400] loss: 1.074\n",
      "[22,   600] loss: 1.075\n",
      "[22,   800] loss: 1.065\n",
      "[22,  1000] loss: 1.069\n",
      "[22,  1200] loss: 1.067\n",
      "[22,  1400] loss: 1.042\n",
      "22 epoch, training accuracy: 62.2620\n",
      "[23,   200] loss: 1.043\n",
      "[23,   400] loss: 1.057\n",
      "[23,   600] loss: 1.062\n",
      "[23,   800] loss: 1.046\n",
      "[23,  1000] loss: 1.043\n",
      "[23,  1200] loss: 1.036\n",
      "[23,  1400] loss: 1.070\n",
      "23 epoch, training accuracy: 62.7080\n",
      "[24,   200] loss: 1.046\n",
      "[24,   400] loss: 1.037\n",
      "[24,   600] loss: 1.033\n",
      "[24,   800] loss: 1.043\n",
      "[24,  1000] loss: 1.059\n",
      "[24,  1200] loss: 1.032\n",
      "[24,  1400] loss: 1.066\n",
      "24 epoch, training accuracy: 63.2860\n",
      "[25,   200] loss: 1.028\n",
      "[25,   400] loss: 1.039\n",
      "[25,   600] loss: 1.038\n",
      "[25,   800] loss: 1.045\n",
      "[25,  1000] loss: 1.050\n",
      "[25,  1200] loss: 1.026\n",
      "[25,  1400] loss: 1.022\n",
      "25 epoch, training accuracy: 63.5320\n",
      "[26,   200] loss: 1.016\n",
      "[26,   400] loss: 1.008\n",
      "[26,   600] loss: 1.028\n",
      "[26,   800] loss: 1.054\n",
      "[26,  1000] loss: 1.034\n",
      "[26,  1200] loss: 1.011\n",
      "[26,  1400] loss: 1.033\n",
      "26 epoch, training accuracy: 63.7860\n",
      "[27,   200] loss: 1.010\n",
      "[27,   400] loss: 1.046\n",
      "[27,   600] loss: 1.036\n",
      "[27,   800] loss: 1.012\n",
      "[27,  1000] loss: 1.008\n",
      "[27,  1200] loss: 1.022\n",
      "[27,  1400] loss: 1.009\n",
      "27 epoch, training accuracy: 63.7620\n",
      "[28,   200] loss: 1.016\n",
      "[28,   400] loss: 0.998\n",
      "[28,   600] loss: 1.013\n",
      "[28,   800] loss: 1.025\n",
      "[28,  1000] loss: 1.025\n",
      "[28,  1200] loss: 0.996\n",
      "[28,  1400] loss: 1.007\n",
      "28 epoch, training accuracy: 64.4820\n",
      "[29,   200] loss: 1.009\n",
      "[29,   400] loss: 1.001\n",
      "[29,   600] loss: 1.009\n",
      "[29,   800] loss: 0.991\n",
      "[29,  1000] loss: 1.013\n",
      "[29,  1200] loss: 1.031\n",
      "[29,  1400] loss: 1.000\n",
      "29 epoch, training accuracy: 64.6080\n",
      "[30,   200] loss: 0.989\n",
      "[30,   400] loss: 1.008\n",
      "[30,   600] loss: 1.003\n",
      "[30,   800] loss: 1.004\n",
      "[30,  1000] loss: 1.026\n",
      "[30,  1200] loss: 1.016\n",
      "[30,  1400] loss: 0.994\n",
      "30 epoch, training accuracy: 64.4880\n",
      "[31,   200] loss: 0.982\n",
      "[31,   400] loss: 1.002\n",
      "[31,   600] loss: 0.991\n",
      "[31,   800] loss: 0.976\n",
      "[31,  1000] loss: 0.976\n",
      "[31,  1200] loss: 0.989\n",
      "[31,  1400] loss: 1.031\n",
      "31 epoch, training accuracy: 65.0480\n",
      "[32,   200] loss: 0.995\n",
      "[32,   400] loss: 0.978\n",
      "[32,   600] loss: 0.988\n",
      "[32,   800] loss: 0.980\n",
      "[32,  1000] loss: 0.987\n",
      "[32,  1200] loss: 1.004\n",
      "[32,  1400] loss: 1.001\n",
      "32 epoch, training accuracy: 65.2000\n",
      "[33,   200] loss: 0.989\n",
      "[33,   400] loss: 0.999\n",
      "[33,   600] loss: 0.980\n",
      "[33,   800] loss: 0.984\n",
      "[33,  1000] loss: 0.988\n",
      "[33,  1200] loss: 0.986\n",
      "[33,  1400] loss: 0.969\n",
      "33 epoch, training accuracy: 65.2740\n",
      "[34,   200] loss: 0.981\n",
      "[34,   400] loss: 0.983\n",
      "[34,   600] loss: 0.985\n",
      "[34,   800] loss: 0.969\n",
      "[34,  1000] loss: 0.975\n",
      "[34,  1200] loss: 0.969\n",
      "[34,  1400] loss: 0.992\n",
      "34 epoch, training accuracy: 65.6760\n",
      "[35,   200] loss: 0.943\n",
      "[35,   400] loss: 0.996\n",
      "[35,   600] loss: 0.956\n",
      "[35,   800] loss: 0.963\n",
      "[35,  1000] loss: 0.979\n",
      "[35,  1200] loss: 0.971\n",
      "[35,  1400] loss: 0.988\n",
      "35 epoch, training accuracy: 65.8060\n",
      "[36,   200] loss: 0.952\n",
      "[36,   400] loss: 0.981\n",
      "[36,   600] loss: 0.977\n",
      "[36,   800] loss: 0.954\n",
      "[36,  1000] loss: 0.954\n",
      "[36,  1200] loss: 0.994\n",
      "[36,  1400] loss: 0.957\n",
      "36 epoch, training accuracy: 65.9700\n",
      "[37,   200] loss: 0.952\n",
      "[37,   400] loss: 0.948\n",
      "[37,   600] loss: 0.957\n",
      "[37,   800] loss: 0.975\n",
      "[37,  1000] loss: 0.960\n",
      "[37,  1200] loss: 0.954\n",
      "[37,  1400] loss: 0.989\n",
      "37 epoch, training accuracy: 66.1960\n",
      "[38,   200] loss: 0.960\n",
      "[38,   400] loss: 0.961\n",
      "[38,   600] loss: 0.942\n",
      "[38,   800] loss: 0.954\n",
      "[38,  1000] loss: 0.948\n",
      "[38,  1200] loss: 0.974\n",
      "[38,  1400] loss: 0.944\n",
      "38 epoch, training accuracy: 66.1540\n",
      "[39,   200] loss: 0.950\n",
      "[39,   400] loss: 0.955\n",
      "[39,   600] loss: 0.926\n",
      "[39,   800] loss: 0.948\n",
      "[39,  1000] loss: 0.946\n",
      "[39,  1200] loss: 0.961\n",
      "[39,  1400] loss: 0.951\n",
      "39 epoch, training accuracy: 66.5260\n",
      "[40,   200] loss: 0.934\n",
      "[40,   400] loss: 0.953\n",
      "[40,   600] loss: 0.948\n",
      "[40,   800] loss: 0.954\n",
      "[40,  1000] loss: 0.964\n",
      "[40,  1200] loss: 0.940\n",
      "[40,  1400] loss: 0.937\n",
      "40 epoch, training accuracy: 66.6580\n",
      "[41,   200] loss: 0.937\n",
      "[41,   400] loss: 0.937\n",
      "[41,   600] loss: 0.931\n",
      "[41,   800] loss: 0.942\n",
      "[41,  1000] loss: 0.930\n",
      "[41,  1200] loss: 0.946\n",
      "[41,  1400] loss: 0.954\n",
      "41 epoch, training accuracy: 66.6800\n",
      "[42,   200] loss: 0.921\n",
      "[42,   400] loss: 0.936\n",
      "[42,   600] loss: 0.946\n",
      "[42,   800] loss: 0.944\n",
      "[42,  1000] loss: 0.923\n",
      "[42,  1200] loss: 0.937\n",
      "[42,  1400] loss: 0.957\n",
      "42 epoch, training accuracy: 66.8540\n",
      "[43,   200] loss: 0.908\n",
      "[43,   400] loss: 0.941\n",
      "[43,   600] loss: 0.921\n",
      "[43,   800] loss: 0.937\n",
      "[43,  1000] loss: 0.931\n",
      "[43,  1200] loss: 0.951\n",
      "[43,  1400] loss: 0.944\n",
      "43 epoch, training accuracy: 67.2140\n",
      "[44,   200] loss: 0.931\n",
      "[44,   400] loss: 0.934\n",
      "[44,   600] loss: 0.904\n",
      "[44,   800] loss: 0.964\n",
      "[44,  1000] loss: 0.947\n",
      "[44,  1200] loss: 0.919\n",
      "[44,  1400] loss: 0.924\n",
      "44 epoch, training accuracy: 67.0560\n",
      "[45,   200] loss: 0.960\n",
      "[45,   400] loss: 0.912\n",
      "[45,   600] loss: 0.921\n",
      "[45,   800] loss: 0.917\n",
      "[45,  1000] loss: 0.928\n",
      "[45,  1200] loss: 0.925\n",
      "[45,  1400] loss: 0.930\n",
      "45 epoch, training accuracy: 67.2480\n",
      "[46,   200] loss: 0.888\n",
      "[46,   400] loss: 0.912\n",
      "[46,   600] loss: 0.922\n",
      "[46,   800] loss: 0.919\n",
      "[46,  1000] loss: 0.930\n",
      "[46,  1200] loss: 0.914\n",
      "[46,  1400] loss: 0.920\n",
      "46 epoch, training accuracy: 67.9040\n",
      "[47,   200] loss: 0.921\n",
      "[47,   400] loss: 0.895\n",
      "[47,   600] loss: 0.951\n",
      "[47,   800] loss: 0.919\n",
      "[47,  1000] loss: 0.894\n",
      "[47,  1200] loss: 0.913\n",
      "[47,  1400] loss: 0.909\n",
      "47 epoch, training accuracy: 67.8840\n",
      "[48,   200] loss: 0.910\n",
      "[48,   400] loss: 0.913\n",
      "[48,   600] loss: 0.903\n",
      "[48,   800] loss: 0.917\n",
      "[48,  1000] loss: 0.924\n",
      "[48,  1200] loss: 0.931\n",
      "[48,  1400] loss: 0.954\n",
      "48 epoch, training accuracy: 67.4740\n",
      "[49,   200] loss: 0.896\n",
      "[49,   400] loss: 0.910\n",
      "[49,   600] loss: 0.906\n",
      "[49,   800] loss: 0.926\n",
      "[49,  1000] loss: 0.914\n",
      "[49,  1200] loss: 0.907\n",
      "[49,  1400] loss: 0.917\n",
      "49 epoch, training accuracy: 67.8720\n",
      "[50,   200] loss: 0.901\n",
      "[50,   400] loss: 0.911\n",
      "[50,   600] loss: 0.918\n",
      "[50,   800] loss: 0.893\n",
      "[50,  1000] loss: 0.919\n",
      "[50,  1200] loss: 0.907\n",
      "[50,  1400] loss: 0.928\n",
      "50 epoch, training accuracy: 68.1300\n",
      "[51,   200] loss: 0.899\n",
      "[51,   400] loss: 0.912\n",
      "[51,   600] loss: 0.906\n",
      "[51,   800] loss: 0.892\n",
      "[51,  1000] loss: 0.903\n",
      "[51,  1200] loss: 0.888\n",
      "[51,  1400] loss: 0.936\n",
      "51 epoch, training accuracy: 68.2760\n",
      "[52,   200] loss: 0.903\n",
      "[52,   400] loss: 0.908\n",
      "[52,   600] loss: 0.888\n",
      "[52,   800] loss: 0.917\n",
      "[52,  1000] loss: 0.888\n",
      "[52,  1200] loss: 0.884\n",
      "[52,  1400] loss: 0.924\n",
      "52 epoch, training accuracy: 68.3660\n",
      "[53,   200] loss: 0.872\n",
      "[53,   400] loss: 0.878\n",
      "[53,   600] loss: 0.887\n",
      "[53,   800] loss: 0.913\n",
      "[53,  1000] loss: 0.919\n",
      "[53,  1200] loss: 0.912\n",
      "[53,  1400] loss: 0.888\n",
      "53 epoch, training accuracy: 68.5720\n",
      "[54,   200] loss: 0.918\n",
      "[54,   400] loss: 0.914\n",
      "[54,   600] loss: 0.873\n",
      "[54,   800] loss: 0.898\n",
      "[54,  1000] loss: 0.892\n",
      "[54,  1200] loss: 0.903\n",
      "[54,  1400] loss: 0.895\n",
      "54 epoch, training accuracy: 68.4860\n",
      "[55,   200] loss: 0.879\n",
      "[55,   400] loss: 0.900\n",
      "[55,   600] loss: 0.881\n",
      "[55,   800] loss: 0.881\n",
      "[55,  1000] loss: 0.892\n",
      "[55,  1200] loss: 0.921\n",
      "[55,  1400] loss: 0.916\n",
      "55 epoch, training accuracy: 68.5060\n",
      "[56,   200] loss: 0.894\n",
      "[56,   400] loss: 0.904\n",
      "[56,   600] loss: 0.894\n",
      "[56,   800] loss: 0.896\n",
      "[56,  1000] loss: 0.888\n",
      "[56,  1200] loss: 0.878\n",
      "[56,  1400] loss: 0.895\n",
      "56 epoch, training accuracy: 68.7160\n",
      "[57,   200] loss: 0.879\n",
      "[57,   400] loss: 0.895\n",
      "[57,   600] loss: 0.877\n",
      "[57,   800] loss: 0.902\n",
      "[57,  1000] loss: 0.914\n",
      "[57,  1200] loss: 0.874\n",
      "[57,  1400] loss: 0.900\n",
      "57 epoch, training accuracy: 68.7260\n",
      "[58,   200] loss: 0.875\n",
      "[58,   400] loss: 0.915\n",
      "[58,   600] loss: 0.857\n",
      "[58,   800] loss: 0.895\n",
      "[58,  1000] loss: 0.895\n",
      "[58,  1200] loss: 0.901\n",
      "[58,  1400] loss: 0.878\n",
      "58 epoch, training accuracy: 68.9420\n",
      "[59,   200] loss: 0.880\n",
      "[59,   400] loss: 0.900\n",
      "[59,   600] loss: 0.900\n",
      "[59,   800] loss: 0.860\n",
      "[59,  1000] loss: 0.874\n",
      "[59,  1200] loss: 0.904\n",
      "[59,  1400] loss: 0.899\n",
      "59 epoch, training accuracy: 68.7840\n",
      "[60,   200] loss: 0.877\n",
      "[60,   400] loss: 0.892\n",
      "[60,   600] loss: 0.890\n",
      "[60,   800] loss: 0.880\n",
      "[60,  1000] loss: 0.879\n",
      "[60,  1200] loss: 0.875\n",
      "[60,  1400] loss: 0.893\n",
      "60 epoch, training accuracy: 69.1280\n",
      "[61,   200] loss: 0.883\n",
      "[61,   400] loss: 0.878\n",
      "[61,   600] loss: 0.869\n",
      "[61,   800] loss: 0.876\n",
      "[61,  1000] loss: 0.874\n",
      "[61,  1200] loss: 0.896\n",
      "[61,  1400] loss: 0.877\n",
      "61 epoch, training accuracy: 69.2120\n",
      "[62,   200] loss: 0.858\n",
      "[62,   400] loss: 0.855\n",
      "[62,   600] loss: 0.880\n",
      "[62,   800] loss: 0.853\n",
      "[62,  1000] loss: 0.893\n",
      "[62,  1200] loss: 0.910\n",
      "[62,  1400] loss: 0.889\n",
      "62 epoch, training accuracy: 69.1100\n",
      "[63,   200] loss: 0.864\n",
      "[63,   400] loss: 0.895\n",
      "[63,   600] loss: 0.877\n",
      "[63,   800] loss: 0.867\n",
      "[63,  1000] loss: 0.854\n",
      "[63,  1200] loss: 0.879\n",
      "[63,  1400] loss: 0.876\n",
      "63 epoch, training accuracy: 69.3660\n",
      "[64,   200] loss: 0.841\n",
      "[64,   400] loss: 0.863\n",
      "[64,   600] loss: 0.889\n",
      "[64,   800] loss: 0.877\n",
      "[64,  1000] loss: 0.878\n",
      "[64,  1200] loss: 0.870\n",
      "[64,  1400] loss: 0.899\n",
      "64 epoch, training accuracy: 69.0940\n",
      "[65,   200] loss: 0.872\n",
      "[65,   400] loss: 0.878\n",
      "[65,   600] loss: 0.863\n",
      "[65,   800] loss: 0.869\n",
      "[65,  1000] loss: 0.884\n",
      "[65,  1200] loss: 0.881\n",
      "[65,  1400] loss: 0.881\n",
      "65 epoch, training accuracy: 69.2200\n",
      "[66,   200] loss: 0.849\n",
      "[66,   400] loss: 0.859\n",
      "[66,   600] loss: 0.867\n",
      "[66,   800] loss: 0.864\n",
      "[66,  1000] loss: 0.883\n",
      "[66,  1200] loss: 0.907\n",
      "[66,  1400] loss: 0.859\n",
      "66 epoch, training accuracy: 69.4760\n",
      "[67,   200] loss: 0.862\n",
      "[67,   400] loss: 0.874\n",
      "[67,   600] loss: 0.839\n",
      "[67,   800] loss: 0.887\n",
      "[67,  1000] loss: 0.856\n",
      "[67,  1200] loss: 0.856\n",
      "[67,  1400] loss: 0.868\n",
      "67 epoch, training accuracy: 69.7700\n",
      "[68,   200] loss: 0.865\n",
      "[68,   400] loss: 0.859\n",
      "[68,   600] loss: 0.851\n",
      "[68,   800] loss: 0.851\n",
      "[68,  1000] loss: 0.854\n",
      "[68,  1200] loss: 0.895\n",
      "[68,  1400] loss: 0.875\n",
      "68 epoch, training accuracy: 69.6460\n",
      "[69,   200] loss: 0.879\n",
      "[69,   400] loss: 0.879\n",
      "[69,   600] loss: 0.862\n",
      "[69,   800] loss: 0.847\n",
      "[69,  1000] loss: 0.879\n",
      "[69,  1200] loss: 0.861\n",
      "[69,  1400] loss: 0.833\n",
      "69 epoch, training accuracy: 69.8900\n",
      "[70,   200] loss: 0.841\n",
      "[70,   400] loss: 0.839\n",
      "[70,   600] loss: 0.868\n",
      "[70,   800] loss: 0.884\n",
      "[70,  1000] loss: 0.853\n",
      "[70,  1200] loss: 0.872\n",
      "[70,  1400] loss: 0.853\n",
      "70 epoch, training accuracy: 69.8880\n",
      "[71,   200] loss: 0.853\n",
      "[71,   400] loss: 0.857\n",
      "[71,   600] loss: 0.857\n",
      "[71,   800] loss: 0.861\n",
      "[71,  1000] loss: 0.855\n",
      "[71,  1200] loss: 0.867\n",
      "[71,  1400] loss: 0.856\n",
      "71 epoch, training accuracy: 70.0340\n",
      "[72,   200] loss: 0.848\n",
      "[72,   400] loss: 0.850\n",
      "[72,   600] loss: 0.839\n",
      "[72,   800] loss: 0.858\n",
      "[72,  1000] loss: 0.881\n",
      "[72,  1200] loss: 0.862\n",
      "[72,  1400] loss: 0.856\n",
      "72 epoch, training accuracy: 69.9320\n",
      "[73,   200] loss: 0.864\n",
      "[73,   400] loss: 0.860\n",
      "[73,   600] loss: 0.830\n",
      "[73,   800] loss: 0.889\n",
      "[73,  1000] loss: 0.847\n",
      "[73,  1200] loss: 0.842\n",
      "[73,  1400] loss: 0.872\n",
      "73 epoch, training accuracy: 69.8300\n",
      "[74,   200] loss: 0.839\n",
      "[74,   400] loss: 0.826\n",
      "[74,   600] loss: 0.868\n",
      "[74,   800] loss: 0.870\n",
      "[74,  1000] loss: 0.862\n",
      "[74,  1200] loss: 0.847\n",
      "[74,  1400] loss: 0.878\n",
      "74 epoch, training accuracy: 70.1440\n",
      "[75,   200] loss: 0.847\n",
      "[75,   400] loss: 0.861\n",
      "[75,   600] loss: 0.871\n",
      "[75,   800] loss: 0.842\n",
      "[75,  1000] loss: 0.837\n",
      "[75,  1200] loss: 0.856\n",
      "[75,  1400] loss: 0.860\n",
      "75 epoch, training accuracy: 70.1700\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Set the model in training mode\n",
    "#because some function like: dropout, batchnorm...etc, will have \n",
    "#different behaviors in training/evaluation mode\n",
    "#[document]: https://pytorch.org/docs/stable/nn.html#torch.nn.Module.train\n",
    "net.train()\n",
    "\n",
    "for epoch in range(75):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        \n",
    "        #change the type into cuda tensor \n",
    "        inputs = inputs.to(device) \n",
    "        labels = labels.to(device) \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        # select the class with highest probability\n",
    "        _, pred = outputs.max(1)\n",
    "        # if the model predicts the same results as the true\n",
    "        # label, then the correct counter will plus 1\n",
    "        correct += pred.eq(labels).sum().item()\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 200 == 199:    # print every 200 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 200))\n",
    "            running_loss = 0.0\n",
    "    print('%d epoch, training accuracy: %.4f' % (epoch+1, 100.*correct/len(trainset)))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Saving model..\n",
      "Finished Saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#After training , save the model first\n",
    "#You can saves only the model parameters or entire model\n",
    "#Some difference between the two is that entire model \n",
    "#not only include parameters but also record how each \n",
    "#layer is connected(forward method).\n",
    "#[document]: https://pytorch.org/docs/master/notes/serialization.html\n",
    "\n",
    "print('==> Saving model..')\n",
    "\n",
    "#only save model parameters\n",
    "torch.save(net.state_dict(), './checkpoint.t7')\n",
    "#you also can store some log information\n",
    "state = {\n",
    "    'net': net.state_dict(),\n",
    "    'acc': 100.*correct/len(trainset),\n",
    "    'epoch': 75\n",
    "}\n",
    "torch.save(state, './checkpoint.t7')\n",
    "\n",
    "#save entire model\n",
    "torch.save(net, './model.pt')\n",
    "\n",
    "print('Finished Saving')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########################################################################\n",
    "\n",
    "# 5. Test the network on the test data\n",
    "\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading model..\n",
      "Finished Loading\n"
     ]
    }
   ],
   "source": [
    "#Before testing, we can load the saved model\n",
    "#Depend on how you save your model, need \n",
    "#different way to use it\n",
    "\n",
    "print('==> Loading model..')\n",
    "\n",
    "#If you just save the model parameters, you\n",
    "#need to redefine the model architecture, and\n",
    "#load the parameters into your model\n",
    "net = Net()\n",
    "checkpoint = torch.load('./checkpoint.t7')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "\n",
    "#If you save the entire model\n",
    "net = torch.load('./model.pt')\n",
    "\n",
    "print('Finished Loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Testing model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('==> Testing model..')\n",
    "\n",
    "#Set the model in evaluation mode\n",
    "#[document]: https://pytorch.org/docs/stable/nn.html#torch.nn.Module.eval \n",
    "net.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
